{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7576ffb-492e-43d2-9af4-28ca1c76abdb",
   "metadata": {},
   "source": [
    "# CSV Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c13059-c950-4532-a90e-b800fd53f744",
   "metadata": {},
   "source": [
    "In the last chapter, we found a directory called `data`. We know Boreas was using this data to choose his vacation location.\n",
    "\n",
    "Each file contains hourly temperature data for a U.S. national park. Our mission: combine them into a single dataset so we can figure out which park is the coldest and then find Boreas!\n",
    "\n",
    "We'll learn how to:\n",
    "\n",
    "- Read .csv files with pandas\n",
    "- Extract metadata (lat/lon/park name) from filenames\n",
    "- Combine data into a single, gridded xarray.Dataset\n",
    "- Save it as a NetCDF file for easy analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e6784d-fe07-4d8c-ad11-c7e7f02c9b8b",
   "metadata": {},
   "source": [
    "## Step 1: Explore the data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82790a6-0235-4871-a97c-4afcd5361b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723e6a5d-fc15-476e-9a78-ef083788d028",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('data')\n",
    "print(f'There are {len(files)} files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4512bce-3987-4322-a3ae-83dc4b50ba1e",
   "metadata": {},
   "source": [
    "Woah! Look at all of those files! We have to process all of that?!\n",
    "\n",
    "Maybe we can find a way to make it easier to process all of the data at once. Let's investigate of few of the filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30b6055-7b31-4bef-ade3-47c7595dc9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files[:5]:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87f854f-3888-4d59-82d7-1a4625a52e1e",
   "metadata": {},
   "source": [
    "Hmmm. There seems to be a specific format for the file names. It appears to be something like (just guessing here, based off of the fact that I made the data) `ParkName_Longitude_Latitude_.csv`\n",
    "\n",
    "Let's crack one open and take a look at what's inside. One of the best packages for processing data in python is [pandas](https://pandas.pydata.org/docs/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3a4cc3-b3a2-4dd2-a9bb-b1d15415afb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Yellowstone-National-Park_249.411484_44.423691_.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fc1c50-7138-413e-8afa-4f6dd961f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02369710-5cab-4a58-b5cf-ea4eb935e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a093541f-ba86-46fb-8748-66ff74007562",
   "metadata": {},
   "source": [
    "We know that Boreas is searching for the national park with the coldest temperature, and we’ve got 70 CSV files, one for each park, each with about 2,920 rows of hourly temperature data.\n",
    "\n",
    "We could write a loop that goes through each file, reads in the data, tracks the minimum temperature in each park, and finds the lowest of them all. That would work fine for this small example. We’ve already shown how to calculate summary statistics from individual CSVs.\n",
    "\n",
    "But what if we were working with a million locations around the globe, each with years of data? Reading one file at a time would quickly become slow, repetitive, and hard to scale.\n",
    "\n",
    "This is where NetCDF comes in. NetCDF is a powerful format for working with large, structured datasets like gridded or time series environmental data.\n",
    "\n",
    "By converting our CSVs into a single NetCDF file, we can organize the data along meaningful dimensions like location and time. Then we can use tools like [xarray](https://docs.xarray.dev/en/stable/) to compute operations, such as the minimum temperature across time at each park, all at once.\n",
    "\n",
    "This kind of transformation makes it much easier to answer questions that involve comparing across datasets, especially as the data size grows.\n",
    "\n",
    "Let's do that transformation now! First, how do we get the name, lat, and lon as it's own data variable? String operations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b7e46f-e484-434b-b3cd-b9761b77700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417a94c3-a412-47a5-af76-c455bd600c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e34ed9-d4b2-4235-961c-f4697c3e30a7",
   "metadata": {},
   "source": [
    "So we need to split that data into parts. [String splitting](https://docs.python.org/3/library/stdtypes.html#str.split) to the rescue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc5b7c0-76c9-4fa1-aa56-da57d773f8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.split('_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7efeca2-0420-4b3f-b635-d59506248e64",
   "metadata": {},
   "source": [
    "Cool, `split`ing along an `_` gives us a list with the name in the first position, longitude in the second, and latitude in the third!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fa13a6-9d26-4a20-926d-c362c710526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = file.split('_')\n",
    "name = split[0]\n",
    "lon = split[1]\n",
    "lat = split[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2443f64c-8542-4257-a43b-d88671fd909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{name} is at ({lon}, {lat})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53989af5-da7e-4e11-9dc3-1bd44ff00506",
   "metadata": {},
   "source": [
    "Now we know how to get the metadata. Let's look at how we can create an xarray dataset. We'll make some toy datasets to illustrate how we can turn CSV tabular data into a gridded dataset, and then you can expand on the example to combine all 70 files. \n",
    "\n",
    "The key points are\n",
    "- Add location information\n",
    "- Stack multiple datasets together\n",
    "- Make a grid. To make this tutorial easy, I will give you the grid you should use, but in practice you would have to define this yourself.\n",
    "- Let pandas do some magic to create a gridded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335c5cdf-8e31-4462-b45c-67a37bef11e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\n",
    "    \"time\": pd.date_range(\"2020-01-01\", periods=3, freq=\"D\"),\n",
    "    \"temperature\": [10, 1, 33],\n",
    "})\n",
    "df1['park'] = \"Yellowstone\"\n",
    "df1['lat'] = 44.6\n",
    "df1['lon'] = -110.5\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    \"time\": pd.date_range(\"2020-01-01\", periods=3, freq=\"D\"),\n",
    "    \"temperature\": [30, 5, 25],\n",
    "})\n",
    "df2[\"park\"] = \"Grand Canyon\"\n",
    "df2[\"lat\"] = 36.1\n",
    "df2[\"lon\"] = -112.1\n",
    "\n",
    "df3 = pd.DataFrame({\n",
    "    \"time\": pd.date_range(\"2020-01-01\", periods=3, freq=\"D\"),\n",
    "    \"temperature\": [10, 20, 30],\n",
    "})\n",
    "df3[\"park\"] = \"Denali\"\n",
    "df3[\"lat\"] = 63.1\n",
    "df3[\"lon\"] = -151.0\n",
    "\n",
    "display(df1)\n",
    "display(df2)\n",
    "display(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20310c1a-f0dd-47b8-8552-5f150d1b213a",
   "metadata": {},
   "source": [
    "Now we want to combine these datasets, first we need to stack them, one on top of the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e56e83-18fd-4f3f-b80e-f76c850b922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df1, df2, df3], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52a0af6-0e51-43a1-b936-ca1d1567e998",
   "metadata": {},
   "source": [
    "Now let's setup a grid. In practice you would need to figure out what grid you need for your data, but for this toy example and for the actual assignment of this notebook, we will provide you the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45909b5-5280-4504-b87e-1bc3ed9bf109",
   "metadata": {},
   "outputs": [],
   "source": [
    "lats = np.arange(30, 75, 5)\n",
    "lons = np.arange(-160, -95, 5)\n",
    "times = pd.date_range(\"2020-01-01\", periods=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58391e4d-39f7-4db6-b94f-8db2b8491ebe",
   "metadata": {},
   "source": [
    "Next, we need to create an xarray dataset that we can assign data to. We will grid it on latitude, longitude, and time. The temperature variable will be on the lat/lon/time grid, will the park name will only be on the lat/lon grid. We will use a `NaN` value (not a number) for the default grid value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8986355a-e65f-43c3-ad51-4a448641eafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.Dataset(\n",
    "    {\n",
    "        \"temperature\": ((\"lat\", \"lon\", \"time\"), np.full((len(lats), len(lons), len(times)), np.nan)),\n",
    "        \"park_name\": ((\"lat\", \"lon\"), np.full((len(lats), len(lons)), \"\", dtype=object)),\n",
    "    },\n",
    "    coords={\"lat\": lats, \"lon\": lons, \"time\": times},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d600a9-9a3f-42d8-87c8-53a36dbc454a",
   "metadata": {},
   "source": [
    "Next we need to iterate over the stacked dataframe in groups using [pandas groupby](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html). We will select the grid value that most closely matches the location of the file, and then assign the temperature and park name accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0059b055-9edd-46d1-bcfe-f01e753f83f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (park, lat, lon), group in df_all.groupby([\"park\", \"lat\", \"lon\"]):\n",
    "    # Select nearest grid cell\n",
    "    sel = ds.sel(lat=lat, lon=lon, method=\"nearest\")\n",
    "    lat_sel = sel.lat.values.item()\n",
    "    lon_sel = sel.lon.values.item()\n",
    "    \n",
    "    temps = group[\"temperature\"].values\n",
    "    ds[\"temperature\"].loc[dict(lat=lat_sel, lon=lon_sel)] = temps\n",
    "    \n",
    "    # Assign park name for that cell\n",
    "    ds[\"park_name\"].loc[dict(lat=lat_sel, lon=lon_sel)] = park"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e16cc5-570b-4993-9612-714846284b36",
   "metadata": {},
   "source": [
    "After all of that work, we have one dataset with temperature values and names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249a4fd6-c3ea-4ae1-a5fc-38f7db74c265",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c676e5-8801-4bac-89f4-78b7290ebab4",
   "metadata": {},
   "source": [
    "To verify, let's make a quick plot. We will show you how to make fancier plots in the next notebook, but for now this is good enough to see that your data got in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3683cb-c5ca-41bb-bb6b-4cfa7d2c6617",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = ds.temperature.min(), ds.temperature.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9948ea-e9e4-40f5-bf2a-39968aa07ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.isel(time=0)['temperature'].plot(vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53849f0a-897e-49e8-9f4e-2ba3e475c125",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.isel(time=1)['temperature'].plot(vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ef2fe7-fcf2-403a-942c-7194fca06ba4",
   "metadata": {},
   "source": [
    "Then, to save the dataset off to a netcdf file, simply tell xarray to do that for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c2c37a-a487-4fa5-8165-117a0ae26397",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_netcdf(\"example.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686e7058-99c6-46bc-ac8f-3ddebfa704f0",
   "metadata": {},
   "source": [
    "## Now You Try: Process the Full Dataset\n",
    "\n",
    "Now you know enough to make your own netcdf dataset using all of the data files you have! We've left some shell code below and predefined variables for you to use to do this work. Please don't spend too long on this, if yout get stuck, we have premade solutions as well as datasets that you can use for the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b223ae2a-0a2e-4d21-8468-9ce69947083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "longitudes = np.arange(200, 331, 2.5)\n",
    "latitudes = np.arange(75, 14, -2.5)\n",
    "times = pd.date_range(start=\"2013-01-01\", end=\"2014-12-31 18:00:00\", freq=\"6H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164f5fcd-b702-457f-9224-fc8c476997f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through each file\n",
    "# split its name and pull out the park name, the latitude, and the longitude\n",
    "# append that to a list of dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25c6ddf-20d3-45e0-bade-440d1a7841bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# below is a gridded dataset that we can use to assign values to\n",
    "ds = xr.Dataset(\n",
    "    {\n",
    "        \"temperature\": ((\"lat\", \"lon\", \"time\"), np.full((len(latitudes), len(longitudes), len(times)), np.nan)),\n",
    "        \"park_name\": ((\"lat\", \"lon\"), np.full((len(latitudes), len(longitudes)), \"\", dtype=object)),\n",
    "    },\n",
    "    coords={\"lat\": latitudes, \"lon\": longitudes, \"time\": times},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f46adf-c766-4c03-a528-9cd628f2d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3308ce2b-1869-4e3f-ba77-af67e24edf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatentate the dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d4fc41-db7f-46a4-9c0e-1e13abd3d600",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for (park, lat, lon), group in df_all.groupby([\"park\", \"lat\", \"lon\"]):\n",
    "    print(f\"{park} at ({lon}, {lat}\")\n",
    "    display(group)\n",
    "    # Select nearest grid cell\n",
    "\n",
    "    # grab the temperature values\n",
    "    temps = group[\"air\"].values\n",
    "\n",
    "    # assign them to the dataset's temperature\n",
    "    \n",
    "    # Assign park name for that cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9094ac33-9d0a-45f9-851c-46d884790841",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056d2781-b770-4f68-a613-15a2e6fd232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_netcdf(\"national_park_temperatures.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d79520-438c-461c-9ef8-3dcb15833328",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.isel(time=0)['temperature'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72636d6-adc6-4997-88e6-6789c558db05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
